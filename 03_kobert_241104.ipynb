{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOHYi/eh0AOt4O5ivL/fuPx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f1f5e8a422de4b63aabbf9c6e8567e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_957991ca75044fd6a010f2b9cf3cb342",
              "IPY_MODEL_2c5063f1c42d4c65be5f716284c64409",
              "IPY_MODEL_72b45a2c3c5d42a3b0459fc3f745840d"
            ],
            "layout": "IPY_MODEL_fd2aaa6324f7458d9cfd8b46bd4b1a39"
          }
        },
        "957991ca75044fd6a010f2b9cf3cb342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac652cd7bb6b481fa203981e7caa61cc",
            "placeholder": "​",
            "style": "IPY_MODEL_9564b16058ed40a88802a3aea1679b1a",
            "value": "100%"
          }
        },
        "2c5063f1c42d4c65be5f716284c64409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6fdf21a9128474cbf4271b452f5e475",
            "max": 453,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6aedf5d5046411fb7012ee3f2d23cd1",
            "value": 453
          }
        },
        "72b45a2c3c5d42a3b0459fc3f745840d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cedfcfed71b6489fb1e868a0be5734f8",
            "placeholder": "​",
            "style": "IPY_MODEL_9b4e15c29f954ad8a586009e38f393ff",
            "value": " 453/453 [04:21&lt;00:00,  2.06it/s]"
          }
        },
        "fd2aaa6324f7458d9cfd8b46bd4b1a39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac652cd7bb6b481fa203981e7caa61cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9564b16058ed40a88802a3aea1679b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6fdf21a9128474cbf4271b452f5e475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6aedf5d5046411fb7012ee3f2d23cd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cedfcfed71b6489fb1e868a0be5734f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b4e15c29f954ad8a586009e38f393ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3388838ed1184d52ad4d8e55d21f3f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33a9da63c8d54dda9678d1279aa626b9",
              "IPY_MODEL_09ee7d3240eb46d4b2f180f1c5690a49",
              "IPY_MODEL_524efe1df4bc443fb2b7544bd76ae9cd"
            ],
            "layout": "IPY_MODEL_bbc5094ac083496db0d761927187bfb3"
          }
        },
        "33a9da63c8d54dda9678d1279aa626b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4f438a1372b49ee81076f947ead0d9c",
            "placeholder": "​",
            "style": "IPY_MODEL_dd7543e204b84a14aa88ae47f4f46916",
            "value": "100%"
          }
        },
        "09ee7d3240eb46d4b2f180f1c5690a49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e95704fa89c34c6983c3432557820ebd",
            "max": 151,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e8b88e5835e47a2b4f4b3bf883d6faf",
            "value": 151
          }
        },
        "524efe1df4bc443fb2b7544bd76ae9cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_394c9a867b6c4db196ab1656906634b4",
            "placeholder": "​",
            "style": "IPY_MODEL_b1d3c1bbbedc4ebcbb7863aed922c5ae",
            "value": " 151/151 [00:31&lt;00:00,  5.05it/s]"
          }
        },
        "bbc5094ac083496db0d761927187bfb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4f438a1372b49ee81076f947ead0d9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd7543e204b84a14aa88ae47f4f46916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e95704fa89c34c6983c3432557820ebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e8b88e5835e47a2b4f4b3bf883d6faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "394c9a867b6c4db196ab1656906634b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1d3c1bbbedc4ebcbb7863aed922c5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eeun-ju/NLP-study/blob/main/03_kobert_241104.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab 환경 설정"
      ],
      "metadata": {
        "id": "Gn9e-ubQ4WPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KoBERT를 이용하여 한국어 문장을 여러 클래스로 분류하는 모델 생성\n",
        "공포, 놀람, 분노, 슬픔, 중립, 행복, 혐오 7개 감정 다중분류 문제"
      ],
      "metadata": {
        "id": "-AcpHm99QLYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://velog.io/@seolini43/KOBERT%EB%A1%9C-%EB%8B%A4%EC%A4%91-%EB%B6%84%EB%A5%98-%EB%AA%A8%EB%8D%B8-%EB%A7%8C%EB%93%A4%EA%B8%B0-%ED%8C%8C%EC%9D%B4%EC%8D%ACColab"
      ],
      "metadata": {
        "id": "PuWr7c9OT2ZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mxnet\n",
        "!pip install gluonnlp==0.8.0\n",
        "!pip install tqdm pandas\n",
        "!pip install sentencepiece\n",
        "!pip install transformers\n",
        "!pip install torch>=1.8.1\n",
        "!pip install numpy==1.23.1\n",
        "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'"
      ],
      "metadata": {
        "id": "6bB35TLVpFY6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "2ace8009-b9a0-4aa2-82c9-11d836a18b93"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mxnet\n",
            "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (2.32.3)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet)\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2024.8.30)\n",
            "Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.3\n",
            "    Uninstalling graphviz-0.20.3:\n",
            "      Successfully uninstalled graphviz-0.20.3\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.1\n",
            "Collecting gluonnlp==0.8.0\n",
            "  Downloading gluonnlp-0.8.0.tar.gz (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gluonnlp==0.8.0) (1.26.4)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.8.0-py3-none-any.whl size=292695 sha256=d07f813e5e9d4df162824c233d04fca6336ce9e3cd5aa7501824f7416ebe8f5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/cc/dc/7ec84dced25f738b8be400101abb67e4b50c905090a51017e4\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.8.0\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Collecting numpy==1.23.1\n",
            "  Downloading numpy-1.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Downloading numpy-1.23.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.19 requires numpy>=1.24.4, but you have numpy 1.23.1 which is incompatible.\n",
            "albumentations 1.4.20 requires numpy>=1.24.4, but you have numpy 1.23.1 which is incompatible.\n",
            "bigframes 1.25.0 requires numpy>=1.24.0, but you have numpy 1.23.1 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.1 which is incompatible.\n",
            "ibis-framework 9.2.0 requires numpy<3,>=1.23.2, but you have numpy 1.23.1 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.1 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.1 which is incompatible.\n",
            "mizani 0.13.0 requires numpy>=1.23.5, but you have numpy 1.23.1 which is incompatible.\n",
            "pandas-stubs 2.2.2.240909 requires numpy>=1.23.5, but you have numpy 1.23.1 which is incompatible.\n",
            "plotnine 0.14.0 requires numpy>=1.23.5, but you have numpy 1.23.1 which is incompatible.\n",
            "tensorflow 2.17.0 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.23.1 which is incompatible.\n",
            "xarray 2024.10.0 requires numpy>=1.24, but you have numpy 1.23.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "fd89a1796bea40e1b4da780e0318b19b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kobert_tokenizer\n",
            "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-9fyivg0q/kobert-tokenizer_2e937f7ec2a24f8c98d1501f6302fa1b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-9fyivg0q/kobert-tokenizer_2e937f7ec2a24f8c98d1501f6302fa1b\n",
            "  Resolved https://github.com/SKTBrain/KoBERT.git to commit 5c46b1c68e4755b54879431bd302db621f4d2f47\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: kobert_tokenizer\n",
            "  Building wheel for kobert_tokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert_tokenizer: filename=kobert_tokenizer-0.1-py3-none-any.whl size=4633 sha256=1966a1652a74cb52a52fe1bdabc2de74b051b5103a9d7bb1ee9f4ba90268bd41\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rcqxzgx2/wheels/e9/1a/3f/a864970e8a169c176befa3c4a1e07aa612f69195907a4045fe\n",
            "Successfully built kobert_tokenizer\n",
            "Installing collected packages: kobert_tokenizer\n",
            "Successfully installed kobert_tokenizer-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook"
      ],
      "metadata": {
        "id": "1j99VqbfzD75",
        "outputId": "17ba2227-ff86-48b2-b4cd-44164880d035",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mxnet/optimizer/optimizer.py:163: UserWarning: WARNING: New optimizer gluonnlp.optimizer.lamb.LAMB is overriding existing optimizer mxnet.optimizer.optimizer.LAMB\n",
            "  warnings.warn('WARNING: New optimizer %s.%s is overriding '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "from transformers import BertModel\n",
        "\n",
        "\n",
        "from transformers import AdamW # 모델의 초기값 지정 함수\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ],
      "metadata": {
        "id": "T1rX8tft5ZOY"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0') # GPU 사용을 위한 설정"
      ],
      "metadata": {
        "id": "Gg-J3s2E5-jj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "n_devices = torch.cuda.device_count()\n",
        "print(n_devices)\n",
        "\n",
        "for i in range(n_devices):\n",
        "    print(torch.cuda.get_device_name(i)) # 0 나오면 GPU 사용 X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mO9pkW_6KEF",
        "outputId": "b2fd35be-ca54-47b2-a0c1-82f287d89856"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlQY7M166abO",
        "outputId": "f4bed515-0350-460e-dd50-e4076b21b14a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1', use_fast = False)\n",
        "bertmodel = BertModel.from_pretrained('skt/kobert-base-v1', return_dict=False)\n",
        "vocab = nlp.vocab.BERTVocab.from_sentencepiece(tokenizer.vocab_file, padding_token='[PAD]')\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mvPQewy6q1j",
        "outputId": "6002f3a7-b0d8-4a85-e09c-b7d083135df8"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
            "The class this function is called from is 'KoBERTTokenizer'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bertmodel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggNgIG17JKI_",
        "outputId": "127d8f00-61ad-4d6b-a92f-ddd50853c837"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#/content/한국어_단발성_대화_데이터셋.xlsx\n",
        "# 한국어 대화 텍스트 데이터, Emotion 감정 레이블\n",
        "import pandas as pd\n",
        "chatbot_data = pd.read_excel('/content/한국어_단발성_대화_데이터셋.xlsx')\n",
        "chatbot_data = chatbot_data[['Sentence','Emotion']]"
      ],
      "metadata": {
        "id": "PfYdxGrq686k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot_data.loc[(chatbot_data['Emotion'] == \"공포\"), 'Emotion'] = 0  #공포 => 0\n",
        "chatbot_data.loc[(chatbot_data['Emotion'] == \"놀람\"), 'Emotion'] = 1  #놀람 => 1\n",
        "chatbot_data.loc[(chatbot_data['Emotion'] == \"분노\"), 'Emotion'] = 2  #분노 => 2\n",
        "chatbot_data.loc[(chatbot_data['Emotion'] == \"슬픔\"), 'Emotion'] = 3  #슬픔 => 3\n",
        "chatbot_data.loc[(chatbot_data['Emotion'] == \"중립\"), 'Emotion'] = 4  #중립 => 4\n",
        "chatbot_data.loc[(chatbot_data['Emotion'] == \"행복\"), 'Emotion'] = 5  #행복 => 5\n",
        "chatbot_data.loc[(chatbot_data['Emotion'] == \"혐오\"), 'Emotion'] = 6  #혐오 => 6\n",
        "\n",
        "data_list = []\n",
        "for q, label in zip(chatbot_data['Sentence'], chatbot_data['Emotion'])  :\n",
        "    data = []\n",
        "    data.append(q)\n",
        "    data.append(str(label))\n",
        "\n",
        "    data_list.append(data)"
      ],
      "metadata": {
        "id": "krIGjAXPIGk0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_list[0])\n",
        "print(data_list[6000])\n",
        "print(data_list[12000])\n",
        "print(data_list[18000])\n",
        "print(data_list[24000])\n",
        "print(data_list[30000])\n",
        "print(data_list[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERywmyUdIfiw",
        "outputId": "3df2fbb1-0e4c-4bdc-9241-abe70d554c9b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['언니 동생으로 부르는게 맞는 일인가요..??', '0']\n",
            "['기술적으로도 아직도 해체해서 다시 완벽히 돌려놓는게 어려운데 해체를한다고?', '1']\n",
            "['당연히 그렇게 해야지 우리나라도 판매를 중단하라', '2']\n",
            "['그거들은 뒤부터 미치겠어요...', '3']\n",
            "['최악의 상황중 그나마 나은 방법이네. 기분은 잡치겠지만', '4']\n",
            "['  요리하는것이 숙제하는것처럼 힘든저에게 용기나게 해주시고 할수 있을것같은 희망을 주셔서감사합니다!!', '5']\n",
            "['와이프도 그렇고 댓글 다 볼텐데 이휘재 좀 하차 하라고 전해주세요', '6']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train & test 데이터로 나누기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset_train, dataset_test = train_test_split(data_list, test_size=0.25, random_state=0)"
      ],
      "metadata": {
        "id": "qVujwhb57-cN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, vocab, max_len,\n",
        "                 pad, pair):\n",
        "        transform = BERTSentenceTransform(bert_tokenizer, max_seq_length=max_len,vocab=vocab, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "metadata": {
        "id": "IK9dc7NH8ARZ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERTSentenceTransform 수정\n",
        "# 모델 입력에 맞춘 형태로 변환\n",
        "class BERTSentenceTransform:\n",
        "    r\"\"\"BERT style data transformation.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tokenizer : BERTTokenizer.\n",
        "        Tokenizer for the sentences.\n",
        "    max_seq_length : int.\n",
        "        Maximum sequence length of the sentences.\n",
        "    pad : bool, default True\n",
        "        Whether to pad the sentences to maximum length.\n",
        "    pair : bool, default True\n",
        "        Whether to transform sentences or sentence pairs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, tokenizer, max_seq_length,vocab, pad=True, pair=True):\n",
        "        self._tokenizer = tokenizer\n",
        "        self._max_seq_length = max_seq_length\n",
        "        self._pad = pad\n",
        "        self._pair = pair\n",
        "        self._vocab = vocab\n",
        "\n",
        "    def __call__(self, line):\n",
        "        \"\"\"Perform transformation for sequence pairs or single sequences.\n",
        "\n",
        "        The transformation is processed in the following steps:\n",
        "        - tokenize the input sequences\n",
        "        - insert [CLS], [SEP] as necessary\n",
        "        - generate type ids to indicate whether a token belongs to the first\n",
        "        sequence or the second sequence.\n",
        "        - generate valid length\n",
        "\n",
        "        For sequence pairs, the input is a tuple of 2 strings:\n",
        "        text_a, text_b.\n",
        "\n",
        "        Inputs:\n",
        "            text_a: 'is this jacksonville ?'\n",
        "            text_b: 'no it is not'\n",
        "        Tokenization:\n",
        "            text_a: 'is this jack ##son ##ville ?'\n",
        "            text_b: 'no it is not .'\n",
        "        Processed:\n",
        "            tokens: '[CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]'\n",
        "            type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
        "            valid_length: 14\n",
        "\n",
        "        For single sequences, the input is a tuple of single string:\n",
        "        text_a.\n",
        "\n",
        "        Inputs:\n",
        "            text_a: 'the dog is hairy .'\n",
        "        Tokenization:\n",
        "            text_a: 'the dog is hairy .'\n",
        "        Processed:\n",
        "            text_a: '[CLS] the dog is hairy . [SEP]'\n",
        "            type_ids: 0     0   0   0  0     0 0\n",
        "            valid_length: 7\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        line: tuple of str\n",
        "            Input strings. For sequence pairs, the input is a tuple of 2 strings:\n",
        "            (text_a, text_b). For single sequences, the input is a tuple of single\n",
        "            string: (text_a,).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array: input token ids in 'int32', shape (batch_size, seq_length)\n",
        "        np.array: valid length in 'int32', shape (batch_size,)\n",
        "        np.array: input token type ids in 'int32', shape (batch_size, seq_length)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # convert to unicode\n",
        "        text_a = line[0]\n",
        "        if self._pair:\n",
        "            assert len(line) == 2\n",
        "            text_b = line[1]\n",
        "\n",
        "        tokens_a = self._tokenizer.tokenize(text_a)\n",
        "        tokens_b = None\n",
        "\n",
        "        if self._pair:\n",
        "            tokens_b = self._tokenizer(text_b)\n",
        "\n",
        "        if tokens_b:\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "            # length is less than the specified length.\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "            self._truncate_seq_pair(tokens_a, tokens_b,\n",
        "                                    self._max_seq_length - 3)\n",
        "        else:\n",
        "            # Account for [CLS] and [SEP] with \"- 2\"\n",
        "            if len(tokens_a) > self._max_seq_length - 2:\n",
        "                tokens_a = tokens_a[0:(self._max_seq_length - 2)]\n",
        "\n",
        "        # The embedding vectors for `type=0` and `type=1` were learned during\n",
        "        # pre-training and are added to the wordpiece embedding vector\n",
        "        # (and position vector). This is not *strictly* necessary since\n",
        "        # the [SEP] token unambiguously separates the sequences, but it makes\n",
        "        # it easier for the model to learn the concept of sequences.\n",
        "\n",
        "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "        # the entire model is fine-tuned.\n",
        "        #vocab = self._tokenizer.vocab\n",
        "        vocab = self._vocab\n",
        "        tokens = []\n",
        "        tokens.append(vocab.cls_token) # 문장 앞에 CLS 문장 시작 나타내기\n",
        "        tokens.extend(tokens_a)\n",
        "        tokens.append(vocab.sep_token) # 문장 끝에 문장의 끝 표시\n",
        "        segment_ids = [0] * len(tokens) # 첫 번째 문장은 0\n",
        "\n",
        "        if tokens_b:\n",
        "            tokens.extend(tokens_b)\n",
        "            tokens.append(vocab.sep_token)\n",
        "            segment_ids.extend([1] * (len(tokens) - len(segment_ids))) # 두 번째 문장은 1\n",
        "\n",
        "        input_ids = self._tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # The valid length of sentences. Only real  tokens are attended to.\n",
        "        valid_length = len(input_ids)\n",
        "\n",
        "        if self._pad:\n",
        "            # Zero-pad up to the sequence length.\n",
        "            padding_length = self._max_seq_length - valid_length\n",
        "            # use padding tokens for the rest\n",
        "            input_ids.extend([vocab[vocab.padding_token]] * padding_length)\n",
        "            segment_ids.extend([0] * padding_length)\n",
        "\n",
        "        return np.array(input_ids, dtype='int32'), np.array(valid_length, dtype='int32'),\\\n",
        "            np.array(segment_ids, dtype='int32')\n"
      ],
      "metadata": {
        "id": "ACUT3PDFOxA-"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting parameters\n",
        "max_len = 64\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 1\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate =  5e-5"
      ],
      "metadata": {
        "id": "WJBs3pOyI6hn"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#토큰화\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "data_train = BERTDataset(dataset_train, 0, 1, tokenizer, vocab, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, tokenizer, vocab, max_len, True, False)"
      ],
      "metadata": {
        "id": "Fr7ppD1NJn-8"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train[0]"
      ],
      "metadata": {
        "id": "2LH8XGYZYBY0",
        "outputId": "d213c638-009a-4120-b97d-d74a2508f287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['그냥 멋져유 ~요리할땐 더 멋져유~기부했다고 들었을땐 더더더 멋져부러유~~^^', '5']"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_0 = tokenizer.tokenize(dataset_train[0][0])\n",
        "print(tokens_0)"
      ],
      "metadata": {
        "id": "sLBljosYYDvH",
        "outputId": "c35033ea-a0e3-421a-9215-276baa6b4f9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁그냥', '▁', '멋', '져', '유', '▁', '~', '요', '리', '할', '땐', '▁더', '▁', '멋', '져', '유', '~', '기', '부', '했다고', '▁들', '었', '을', '땐', '▁더', '더', '더', '▁', '멋', '져', '부', '러', '유', '~', '~', '^', '^']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = []\n",
        "tokens.append(vocab.cls_token) # 문장 앞에 CLS 문장 시작 나타내기\n",
        "tokens.extend(tokens_0)\n",
        "tokens.append(vocab.sep_token) # 문장 끝에 문장의 끝 표시"
      ],
      "metadata": {
        "id": "UR4BUSqRYYz2"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens)"
      ],
      "metadata": {
        "id": "VuXziNjVZBs9",
        "outputId": "5a4c064d-09e7-426a-ce8c-65023e4c6178",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', '▁그냥', '▁', '멋', '져', '유', '▁', '~', '요', '리', '할', '땐', '▁더', '▁', '멋', '져', '유', '~', '기', '부', '했다고', '▁들', '었', '을', '땐', '▁더', '더', '더', '▁', '멋', '져', '부', '러', '유', '~', '~', '^', '^', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.convert_tokens_to_ids(tokens)), len(tokenizer.convert_tokens_to_ids(tokens))"
      ],
      "metadata": {
        "id": "aKHgWmkxZkTI",
        "outputId": "52a9e7b9-a037-45d1-ed42-7fee864f67a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 1189, 517, 6188, 7245, 7063, 517, 463, 6999, 6122, 7836, 5966, 1698, 517, 6188, 7245, 7063, 463, 5561, 6398, 7870, 1801, 6885, 7088, 5966, 1698, 5837, 5837, 517, 6188, 7245, 6398, 6037, 7063, 463, 463, 364, 364, 3]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 39)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train[0]\n",
        "\n",
        "# (array([   2, 1189,  517, 6188, 7245, 7063,  517,  463, 6999, 6122, 7836,\n",
        "#         5966, 1698,  517, 6188, 7245, 7063,  463, 5561, 6398, 7870, 1801,\n",
        "#         6885, 7088, 5966, 1698, 5837, 5837,  517, 6188, 7245, 6398, 6037,\n",
        "#         7063,  463,  463,  364,  364,    3,    1,    1,    1,    1,    1,\n",
        "#            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
        "#            1,    1,    1,    1,    1,    1,    1,    1,    1], dtype=int32),\n",
        "#  array(39, dtype=int32),\n",
        "#  array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "#         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "#         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "#        dtype=int32),\n",
        "#  5) 3개의 array\n",
        "# padding sequence\n",
        "# 길이와 타입에 대한 내용\n",
        "# attension mast sequence 연산이 필요한 부분은 0\n",
        "# 1로 패딩된 값들은 연산할 필요가 없음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9SEW5cOPKYP",
        "outputId": "b9b9a250-be31-4d99-e86a-e923cfd942a1"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([   2, 1189,  517, 6188, 7245, 7063,  517,  463, 6999, 6122, 7836,\n",
              "        5966, 1698,  517, 6188, 7245, 7063,  463, 5561, 6398, 7870, 1801,\n",
              "        6885, 7088, 5966, 1698, 5837, 5837,  517, 6188, 7245, 6398, 6037,\n",
              "        7063,  463,  463,  364,  364,    3,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1], dtype=int32),\n",
              " array(39, dtype=int32),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       dtype=int32),\n",
              " 5)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq_-yiEhPoPi",
        "outputId": "5f8e8d5c-5856-45e9-d1a1-f4e4068229d1"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=7,   ##클래스 수 조정##\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "\n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "\n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "\n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "metadata": {
        "id": "9_qeWSdNPqyC"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BERT 모델 불러오기\n",
        "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
        "\n",
        "#optimizer와 schedule 설정\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
        "\n",
        "#정확도 측정을 위한 함수 정의\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc\n",
        "\n",
        "train_dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzs-c-NdPtIF",
        "outputId": "526219b1-6eaf-47ac-f0fa-2f2997b452fc"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7a04b07a6890>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338,
          "referenced_widgets": [
            "f1f5e8a422de4b63aabbf9c6e8567e47",
            "957991ca75044fd6a010f2b9cf3cb342",
            "2c5063f1c42d4c65be5f716284c64409",
            "72b45a2c3c5d42a3b0459fc3f745840d",
            "fd2aaa6324f7458d9cfd8b46bd4b1a39",
            "ac652cd7bb6b481fa203981e7caa61cc",
            "9564b16058ed40a88802a3aea1679b1a",
            "f6fdf21a9128474cbf4271b452f5e475",
            "e6aedf5d5046411fb7012ee3f2d23cd1",
            "cedfcfed71b6489fb1e868a0be5734f8",
            "9b4e15c29f954ad8a586009e38f393ff",
            "3388838ed1184d52ad4d8e55d21f3f98",
            "33a9da63c8d54dda9678d1279aa626b9",
            "09ee7d3240eb46d4b2f180f1c5690a49",
            "524efe1df4bc443fb2b7544bd76ae9cd",
            "bbc5094ac083496db0d761927187bfb3",
            "e4f438a1372b49ee81076f947ead0d9c",
            "dd7543e204b84a14aa88ae47f4f46916",
            "e95704fa89c34c6983c3432557820ebd",
            "7e8b88e5835e47a2b4f4b3bf883d6faf",
            "394c9a867b6c4db196ab1656906634b4",
            "b1d3c1bbbedc4ebcbb7863aed922c5ae"
          ]
        },
        "id": "mbTKiu4xPw-_",
        "outputId": "38564d2c-5978-456a-a1ca-cc0117168d57"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-96-480b6a139979>:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/453 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1f5e8a422de4b63aabbf9c6e8567e47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 batch id 1 loss 2.039832353591919 train acc 0.140625\n",
            "epoch 1 batch id 201 loss 1.2129566669464111 train acc 0.3763992537313433\n",
            "epoch 1 batch id 401 loss 1.163533091545105 train acc 0.4445137157107232\n",
            "epoch 1 train acc 0.4547948318400208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-96-480b6a139979>:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/151 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3388838ed1184d52ad4d8e55d21f3f98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 test acc 0.5383772300310853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(predict_sentence):\n",
        "\n",
        "    data = [predict_sentence, '0']\n",
        "    dataset_another = [data]\n",
        "\n",
        "    another_test = BERTDataset(dataset_another, 0, 1, tokenizer, vocab, max_len, True, False)\n",
        "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "\n",
        "        test_eval=[]\n",
        "        for i in out:\n",
        "            logits=i\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "\n",
        "            if np.argmax(logits) == 0:\n",
        "                test_eval.append(\"공포가\")\n",
        "            elif np.argmax(logits) == 1:\n",
        "                test_eval.append(\"놀람이\")\n",
        "            elif np.argmax(logits) == 2:\n",
        "                test_eval.append(\"분노가\")\n",
        "            elif np.argmax(logits) == 3:\n",
        "                test_eval.append(\"슬픔이\")\n",
        "            elif np.argmax(logits) == 4:\n",
        "                test_eval.append(\"중립이\")\n",
        "            elif np.argmax(logits) == 5:\n",
        "                test_eval.append(\"행복이\")\n",
        "            elif np.argmax(logits) == 6:\n",
        "                test_eval.append(\"혐오가\")\n",
        "\n",
        "        print(\">> 입력하신 내용에서 \" + test_eval[0] + \" 느껴집니다.\")"
      ],
      "metadata": {
        "id": "66IB1oKdSBHp"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end = 1\n",
        "while end == 1 :\n",
        "    sentence = input(\"하고싶은 말을 입력해주세요 : \")\n",
        "    if sentence == 0 :\n",
        "        break\n",
        "    predict(sentence)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "id": "vqgsz4KYSEIf",
        "outputId": "5ff1d09d-f95a-49b4-ba2f-49acf65ae55e"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "하고싶은 말을 입력해주세요 : 집에 가고싶다\n",
            ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
            "\n",
            "\n",
            "하고싶은 말을 입력해주세요 : 마스크 때문에 짜증나\n",
            ">> 입력하신 내용에서 혐오가 느껴집니다.\n",
            "\n",
            "\n",
            "하고싶은 말을 입력해주세요 : 주식이 올랐네\n",
            ">> 입력하신 내용에서 놀람이 느껴집니다.\n",
            "\n",
            "\n",
            "하고싶은 말을 입력해주세요 : 어제 헤어졌어\n",
            ">> 입력하신 내용에서 슬픔이 느껴집니다.\n",
            "\n",
            "\n",
            "하고싶은 말을 입력해주세요 : 0\n",
            ">> 입력하신 내용에서 놀람이 느껴집니다.\n",
            "\n",
            "\n",
            "하고싶은 말을 입력해주세요 : \n",
            ">> 입력하신 내용에서 놀람이 느껴집니다.\n",
            "\n",
            "\n",
            "하고싶은 말을 입력해주세요 : \"0\"\n",
            ">> 입력하신 내용에서 공포가 느껴집니다.\n",
            "\n",
            "\n",
            "하고싶은 말을 입력해주세요 : 0\n",
            ">> 입력하신 내용에서 놀람이 느껴집니다.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-178c55379749>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"하고싶은 말을 입력해주세요 : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KoBERT 모델에서의 토큰화와 정수 인코딩\n",
        "\n",
        "result = tokenizer.tokenize(\"너는 내년 대선 때 투표할 수 있어?\")\n",
        "print(result) # _ 기호 : 문장 내 공백 위치를 나타냄\n",
        "# ['▁너', '는', '▁내년', '▁대선', '▁때', '▁투표', '할', '▁수', '▁있어', '?']\n",
        "# 너 라는 단어가 문장의 시작 위치\n",
        "# 는은 너라는 단어 앞에 붙음"
      ],
      "metadata": {
        "id": "byVuLngKVA7g",
        "outputId": "0d59dc8f-4b21-4e90-a414-76076d726b49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['▁너', '는', '▁내년', '▁대선', '▁때', '▁투표', '할', '▁수', '▁있어', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([tokenizer.encode(token) for token in result])"
      ],
      "metadata": {
        "id": "Z-fY2a4ZU6Cp",
        "outputId": "6538faa7-6144-449f-c745-c4eeefedd58f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 1457, 3], [2, 517, 5760, 3], [2, 1437, 3], [2, 1654, 3], [2, 1844, 3], [2, 4772, 3], [2, 4977, 3], [2, 2872, 3], [2, 3868, 3], [2, 633, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kobert_vocab = tokenizer.get_vocab()\n",
        "print(kobert_vocab.get('▁대선'))"
      ],
      "metadata": {
        "id": "2HqHWmKNVtia",
        "outputId": "b034c3bc-962f-43ae-f729-2be9088b02c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1654\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kobert_vocab"
      ],
      "metadata": {
        "id": "Zz9c4BuEW-01",
        "outputId": "2e5df72c-8c64-4af4-fbc4-02b81e45c3b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'[UNK]': 0,\n",
              " '[PAD]': 1,\n",
              " '[CLS]': 2,\n",
              " '[SEP]': 3,\n",
              " '[MASK]': 4,\n",
              " '!': 5,\n",
              " \"!'\": 6,\n",
              " '!”': 7,\n",
              " '\"': 8,\n",
              " '#': 9,\n",
              " '$': 10,\n",
              " '%': 11,\n",
              " '%)': 12,\n",
              " '&': 13,\n",
              " '&#34;': 14,\n",
              " \"'\": 15,\n",
              " \"'(\": 16,\n",
              " \"',\": 17,\n",
              " '(': 18,\n",
              " '(0': 19,\n",
              " '(1': 20,\n",
              " '(10': 21,\n",
              " '(12': 22,\n",
              " '(15': 23,\n",
              " '(17': 24,\n",
              " '(18': 25,\n",
              " '(19': 26,\n",
              " '(2': 27,\n",
              " '(20': 28,\n",
              " '(23': 29,\n",
              " '(24': 30,\n",
              " '(25': 31,\n",
              " '(3': 32,\n",
              " '(4': 33,\n",
              " '(5': 34,\n",
              " '(6': 35,\n",
              " '(7': 36,\n",
              " '(8': 37,\n",
              " '(9': 38,\n",
              " '(?)': 39,\n",
              " ')': 40,\n",
              " \")'\": 41,\n",
              " '),': 42,\n",
              " ')’': 43,\n",
              " '*': 44,\n",
              " '+': 45,\n",
              " ',': 46,\n",
              " '-': 47,\n",
              " '----------------': 48,\n",
              " '-1': 49,\n",
              " '-2': 50,\n",
              " '-20': 51,\n",
              " '-3': 52,\n",
              " '-4': 53,\n",
              " '.': 54,\n",
              " '...': 55,\n",
              " '...\"': 56,\n",
              " \"...'\": 57,\n",
              " '...”': 58,\n",
              " '/': 59,\n",
              " '0': 60,\n",
              " '0%': 61,\n",
              " '0%)': 62,\n",
              " '0.0': 63,\n",
              " '0.00': 64,\n",
              " '0.1': 65,\n",
              " '0.1%': 66,\n",
              " '0.2%': 67,\n",
              " '0.3': 68,\n",
              " '0.3%': 69,\n",
              " '0.4%': 70,\n",
              " '0.5': 71,\n",
              " '0.5%': 72,\n",
              " '0.6': 73,\n",
              " '0.6%': 74,\n",
              " '0.7': 75,\n",
              " '0.7%': 76,\n",
              " '0.8': 77,\n",
              " '0.8%': 78,\n",
              " '00': 79,\n",
              " '000.0': 80,\n",
              " '00000': 81,\n",
              " '01': 82,\n",
              " '02': 83,\n",
              " '02-': 84,\n",
              " '03': 85,\n",
              " '04': 86,\n",
              " '05': 87,\n",
              " '06': 88,\n",
              " '07': 89,\n",
              " '08': 90,\n",
              " '09': 91,\n",
              " '0:00:00': 92,\n",
              " '1': 93,\n",
              " '1%': 94,\n",
              " '1%)': 95,\n",
              " '1)': 96,\n",
              " '1,000': 97,\n",
              " '1.3%': 98,\n",
              " '1.4%': 99,\n",
              " '1.5%': 100,\n",
              " '1.6': 101,\n",
              " '1.6%': 102,\n",
              " '1.7%': 103,\n",
              " '1.8': 104,\n",
              " '10': 105,\n",
              " '100': 106,\n",
              " '1000': 107,\n",
              " '11': 108,\n",
              " '12': 109,\n",
              " '13': 110,\n",
              " '14': 111,\n",
              " '15': 112,\n",
              " '16': 113,\n",
              " '17': 114,\n",
              " '18': 115,\n",
              " '19': 116,\n",
              " '1⁄2': 117,\n",
              " '1⁄4': 118,\n",
              " '2': 119,\n",
              " '2%': 120,\n",
              " '2)': 121,\n",
              " '2.0': 122,\n",
              " '2.3%': 123,\n",
              " '2.5': 124,\n",
              " '2.5%': 125,\n",
              " '2.8%': 126,\n",
              " '20': 127,\n",
              " '200': 128,\n",
              " '2000': 129,\n",
              " '2011': 130,\n",
              " '2012': 131,\n",
              " '2013': 132,\n",
              " '21': 133,\n",
              " '22': 134,\n",
              " '23': 135,\n",
              " '24': 136,\n",
              " '25': 137,\n",
              " '26': 138,\n",
              " '27': 139,\n",
              " '28': 140,\n",
              " '29': 141,\n",
              " '3': 142,\n",
              " '3%': 143,\n",
              " '30': 144,\n",
              " '300': 145,\n",
              " '3000': 146,\n",
              " '31': 147,\n",
              " '32': 148,\n",
              " '33': 149,\n",
              " '34': 150,\n",
              " '35': 151,\n",
              " '36': 152,\n",
              " '37': 153,\n",
              " '38': 154,\n",
              " '39': 155,\n",
              " '3⁄4': 156,\n",
              " '4': 157,\n",
              " '4%': 158,\n",
              " '4%)': 159,\n",
              " '40': 160,\n",
              " '400': 161,\n",
              " '4000': 162,\n",
              " '41': 163,\n",
              " '42': 164,\n",
              " '43': 165,\n",
              " '44': 166,\n",
              " '45': 167,\n",
              " '46': 168,\n",
              " '47': 169,\n",
              " '48': 170,\n",
              " '49': 171,\n",
              " '5': 172,\n",
              " '5%': 173,\n",
              " '5%)': 174,\n",
              " '5,000': 175,\n",
              " '50': 176,\n",
              " '500': 177,\n",
              " '5000': 178,\n",
              " '51': 179,\n",
              " '52': 180,\n",
              " '53': 181,\n",
              " '54': 182,\n",
              " '55': 183,\n",
              " '56': 184,\n",
              " '57': 185,\n",
              " '58': 186,\n",
              " '59': 187,\n",
              " '6': 188,\n",
              " '6%': 189,\n",
              " '60': 190,\n",
              " '600': 191,\n",
              " '6000': 192,\n",
              " '61': 193,\n",
              " '62': 194,\n",
              " '63': 195,\n",
              " '64': 196,\n",
              " '65': 197,\n",
              " '66': 198,\n",
              " '67': 199,\n",
              " '68': 200,\n",
              " '69': 201,\n",
              " '7': 202,\n",
              " '7%': 203,\n",
              " '7%)': 204,\n",
              " '7.0': 205,\n",
              " '7.5%': 206,\n",
              " '70': 207,\n",
              " '700': 208,\n",
              " '7000': 209,\n",
              " '71': 210,\n",
              " '72': 211,\n",
              " '73': 212,\n",
              " '74': 213,\n",
              " '75': 214,\n",
              " '76': 215,\n",
              " '77': 216,\n",
              " '78': 217,\n",
              " '79': 218,\n",
              " '8': 219,\n",
              " '8%': 220,\n",
              " '8%)': 221,\n",
              " '80': 222,\n",
              " '800': 223,\n",
              " '8000': 224,\n",
              " '81': 225,\n",
              " '82': 226,\n",
              " '83': 227,\n",
              " '84': 228,\n",
              " '85': 229,\n",
              " '86': 230,\n",
              " '87': 231,\n",
              " '88': 232,\n",
              " '89': 233,\n",
              " '9': 234,\n",
              " '9%': 235,\n",
              " '9%)': 236,\n",
              " '90': 237,\n",
              " '900': 238,\n",
              " '9000': 239,\n",
              " '91': 240,\n",
              " '92': 241,\n",
              " '93': 242,\n",
              " '94': 243,\n",
              " '95': 244,\n",
              " '96': 245,\n",
              " '97': 246,\n",
              " '98': 247,\n",
              " '99': 248,\n",
              " ':': 249,\n",
              " '://': 250,\n",
              " ':00': 251,\n",
              " ';': 252,\n",
              " '<': 253,\n",
              " '=': 254,\n",
              " '=\"\"': 255,\n",
              " '=\"\">': 256,\n",
              " '>': 257,\n",
              " '?': 258,\n",
              " '?\"': 259,\n",
              " '??': 260,\n",
              " '???': 261,\n",
              " '????': 262,\n",
              " '?”': 263,\n",
              " 'A': 264,\n",
              " 'AM': 265,\n",
              " 'AP': 266,\n",
              " 'AR': 267,\n",
              " 'AS': 268,\n",
              " 'AT': 269,\n",
              " 'B': 270,\n",
              " 'BC': 271,\n",
              " 'BO': 272,\n",
              " 'BS': 273,\n",
              " 'C': 274,\n",
              " 'CC': 275,\n",
              " 'CD': 276,\n",
              " 'CI': 277,\n",
              " 'D': 278,\n",
              " 'DB': 279,\n",
              " 'DC': 280,\n",
              " 'DI': 281,\n",
              " 'E': 282,\n",
              " 'ER': 283,\n",
              " 'EU': 284,\n",
              " 'F': 285,\n",
              " 'FC': 286,\n",
              " 'FI': 287,\n",
              " 'FIFA': 288,\n",
              " 'FTA': 289,\n",
              " 'G': 290,\n",
              " 'GB': 291,\n",
              " 'GDP': 292,\n",
              " 'GM': 293,\n",
              " 'H': 294,\n",
              " 'HD': 295,\n",
              " 'I': 296,\n",
              " 'IA': 297,\n",
              " 'IB': 298,\n",
              " 'IC': 299,\n",
              " 'II': 300,\n",
              " 'IM': 301,\n",
              " 'IN': 302,\n",
              " 'IP': 303,\n",
              " 'IS': 304,\n",
              " 'IT': 305,\n",
              " 'J': 306,\n",
              " 'K': 307,\n",
              " 'KB': 308,\n",
              " 'KBS': 309,\n",
              " 'KT': 310,\n",
              " 'L': 311,\n",
              " 'LED': 312,\n",
              " 'LG': 313,\n",
              " 'LPGA': 314,\n",
              " 'LS': 315,\n",
              " 'M': 316,\n",
              " 'MBC': 317,\n",
              " 'MBN': 318,\n",
              " 'MC': 319,\n",
              " 'MOU': 320,\n",
              " 'MS': 321,\n",
              " 'N': 322,\n",
              " 'NA': 323,\n",
              " 'NE': 324,\n",
              " 'NLL': 325,\n",
              " 'NS': 326,\n",
              " 'NTSB': 327,\n",
              " 'New': 328,\n",
              " 'O': 329,\n",
              " 'OC': 330,\n",
              " 'OS': 331,\n",
              " 'OSEN': 332,\n",
              " 'P': 333,\n",
              " 'PC': 334,\n",
              " 'PD': 335,\n",
              " 'PGA': 336,\n",
              " 'PI': 337,\n",
              " 'PM': 338,\n",
              " 'POP': 339,\n",
              " 'PS': 340,\n",
              " 'Q': 341,\n",
              " 'R': 342,\n",
              " 'S': 343,\n",
              " 'SBS': 344,\n",
              " 'SI': 345,\n",
              " 'SK': 346,\n",
              " 'SNS': 347,\n",
              " 'SP': 348,\n",
              " 'SS': 349,\n",
              " 'ST': 350,\n",
              " 'T': 351,\n",
              " 'TI': 352,\n",
              " 'TS': 353,\n",
              " 'TV': 354,\n",
              " 'The': 355,\n",
              " 'U': 356,\n",
              " 'V': 357,\n",
              " 'W': 358,\n",
              " 'X': 359,\n",
              " 'Y': 360,\n",
              " 'Z': 361,\n",
              " '[': 362,\n",
              " ']': 363,\n",
              " '^': 364,\n",
              " '_': 365,\n",
              " '`': 366,\n",
              " 'a': 367,\n",
              " 'ab': 368,\n",
              " 'ac': 369,\n",
              " 'ad': 370,\n",
              " 'al': 371,\n",
              " 'all': 372,\n",
              " 'am': 373,\n",
              " 'an': 374,\n",
              " 'ar': 375,\n",
              " 'as': 376,\n",
              " 'at': 377,\n",
              " 'ation': 378,\n",
              " 'ay': 379,\n",
              " 'b': 380,\n",
              " 'bp': 381,\n",
              " 'c': 382,\n",
              " 'ch': 383,\n",
              " 'cm': 384,\n",
              " 'co': 385,\n",
              " 'com': 386,\n",
              " 'ct': 387,\n",
              " 'd': 388,\n",
              " 'e': 389,\n",
              " 'ed': 390,\n",
              " 'el': 391,\n",
              " 'en': 392,\n",
              " 'ent': 393,\n",
              " 'er': 394,\n",
              " 'es': 395,\n",
              " 'est': 396,\n",
              " 'et': 397,\n",
              " 'f': 398,\n",
              " 'g': 399,\n",
              " 'go': 400,\n",
              " 'h': 401,\n",
              " 'ha': 402,\n",
              " 'ho': 403,\n",
              " 'http': 404,\n",
              " 'i': 405,\n",
              " 'ic': 406,\n",
              " 'id': 407,\n",
              " 'il': 408,\n",
              " 'in': 409,\n",
              " 'ing': 410,\n",
              " 'ir': 411,\n",
              " 'is': 412,\n",
              " 'it': 413,\n",
              " 'j': 414,\n",
              " 'k': 415,\n",
              " 'kW': 416,\n",
              " 'kg': 417,\n",
              " 'km': 418,\n",
              " 'kr': 419,\n",
              " 'l': 420,\n",
              " 'le': 421,\n",
              " 'lo': 422,\n",
              " 'm': 423,\n",
              " 'mm': 424,\n",
              " 'n': 425,\n",
              " 'net': 426,\n",
              " 'o': 427,\n",
              " 'ol': 428,\n",
              " 'on': 429,\n",
              " 'or': 430,\n",
              " 'ow': 431,\n",
              " 'p': 432,\n",
              " 'q': 433,\n",
              " 'quot': 434,\n",
              " 'r': 435,\n",
              " 'ra': 436,\n",
              " 're': 437,\n",
              " 'ri': 438,\n",
              " 'ro': 439,\n",
              " 's': 440,\n",
              " 'st': 441,\n",
              " 't': 442,\n",
              " 'ter': 443,\n",
              " 'th': 444,\n",
              " 'tion': 445,\n",
              " 'u': 446,\n",
              " 'ul': 447,\n",
              " 'um': 448,\n",
              " 'un': 449,\n",
              " 'ur': 450,\n",
              " 'us': 451,\n",
              " 'ut': 452,\n",
              " 'v': 453,\n",
              " 'ver': 454,\n",
              " 'w': 455,\n",
              " 'www': 456,\n",
              " 'x': 457,\n",
              " 'y': 458,\n",
              " 'z': 459,\n",
              " '{': 460,\n",
              " '|': 461,\n",
              " '}': 462,\n",
              " '~': 463,\n",
              " '~1': 464,\n",
              " '~20': 465,\n",
              " '~3': 466,\n",
              " '~5': 467,\n",
              " '~6': 468,\n",
              " '~8': 469,\n",
              " '¡': 470,\n",
              " '¤': 471,\n",
              " '§': 472,\n",
              " '\\xad': 473,\n",
              " '®': 474,\n",
              " '°': 475,\n",
              " '±': 476,\n",
              " '¶': 477,\n",
              " '·': 478,\n",
              " '¿': 479,\n",
              " 'Æ': 480,\n",
              " '×': 481,\n",
              " 'Ø': 482,\n",
              " 'ß': 483,\n",
              " 'æ': 484,\n",
              " '÷': 485,\n",
              " 'ø': 486,\n",
              " '́': 487,\n",
              " '̧': 488,\n",
              " 'μ': 489,\n",
              " 'ᄀ': 490,\n",
              " 'ᄋ': 491,\n",
              " 'ᄏ': 492,\n",
              " 'ᄒ': 493,\n",
              " 'ᅵ': 494,\n",
              " 'ᆞ': 495,\n",
              " '―': 496,\n",
              " '‘': 497,\n",
              " '’': 498,\n",
              " '’(': 499,\n",
              " '’,': 500,\n",
              " '“': 501,\n",
              " '”': 502,\n",
              " '”,': 503,\n",
              " '′': 504,\n",
              " '※': 505,\n",
              " '⁄': 506,\n",
              " '↑': 507,\n",
              " '→': 508,\n",
              " '↓': 509,\n",
              " '↓]': 510,\n",
              " '∼': 511,\n",
              " '─': 512,\n",
              " '───': 513,\n",
              " '│': 514,\n",
              " '├': 515,\n",
              " '┼': 516,\n",
              " '▁': 517,\n",
              " '▁\"': 518,\n",
              " '▁&': 519,\n",
              " \"▁'\": 520,\n",
              " \"▁'2013\": 521,\n",
              " '▁(': 522,\n",
              " '▁*': 523,\n",
              " '▁-': 524,\n",
              " '▁/': 525,\n",
              " '▁0': 526,\n",
              " '▁0.2': 527,\n",
              " '▁00:0': 528,\n",
              " '▁1': 529,\n",
              " '▁1%': 530,\n",
              " '▁1,2': 531,\n",
              " '▁1.5': 532,\n",
              " '▁10': 533,\n",
              " '▁10%': 534,\n",
              " '▁100': 535,\n",
              " '▁100%': 536,\n",
              " '▁1000': 537,\n",
              " '▁11': 538,\n",
              " '▁12': 539,\n",
              " '▁120': 540,\n",
              " '▁13': 541,\n",
              " '▁14': 542,\n",
              " '▁15': 543,\n",
              " '▁150': 544,\n",
              " '▁16': 545,\n",
              " '▁17': 546,\n",
              " '▁18': 547,\n",
              " '▁19': 548,\n",
              " '▁1990': 549,\n",
              " '▁1997': 550,\n",
              " '▁1998': 551,\n",
              " '▁1~2': 552,\n",
              " '▁2': 553,\n",
              " '▁20': 554,\n",
              " '▁20%': 555,\n",
              " '▁200': 556,\n",
              " '▁2000': 557,\n",
              " '▁2001': 558,\n",
              " '▁2002': 559,\n",
              " '▁2003': 560,\n",
              " '▁2004': 561,\n",
              " '▁2005': 562,\n",
              " '▁2006': 563,\n",
              " '▁2007': 564,\n",
              " '▁2008': 565,\n",
              " '▁2009': 566,\n",
              " '▁2010': 567,\n",
              " '▁2011': 568,\n",
              " '▁2012': 569,\n",
              " '▁2013': 570,\n",
              " '▁2013-0': 571,\n",
              " '▁2013.0': 572,\n",
              " '▁2013.07.1': 573,\n",
              " '▁2013.07.2': 574,\n",
              " '▁2014': 575,\n",
              " '▁2015': 576,\n",
              " '▁2016': 577,\n",
              " '▁2017': 578,\n",
              " '▁21': 579,\n",
              " '▁22': 580,\n",
              " '▁23': 581,\n",
              " '▁24': 582,\n",
              " '▁25': 583,\n",
              " '▁26': 584,\n",
              " '▁27': 585,\n",
              " '▁28': 586,\n",
              " '▁29': 587,\n",
              " '▁2~3': 588,\n",
              " '▁3': 589,\n",
              " '▁3.0': 590,\n",
              " '▁3.3': 591,\n",
              " '▁30': 592,\n",
              " '▁30%': 593,\n",
              " '▁300': 594,\n",
              " '▁3000': 595,\n",
              " '▁31': 596,\n",
              " '▁32': 597,\n",
              " '▁33': 598,\n",
              " '▁34': 599,\n",
              " '▁35': 600,\n",
              " '▁36': 601,\n",
              " '▁37': 602,\n",
              " '▁38': 603,\n",
              " '▁39': 604,\n",
              " '▁4': 605,\n",
              " '▁40': 606,\n",
              " '▁40%': 607,\n",
              " '▁400': 608,\n",
              " '▁45': 609,\n",
              " '▁48': 610,\n",
              " '▁5': 611,\n",
              " '▁50': 612,\n",
              " '▁50%': 613,\n",
              " '▁500': 614,\n",
              " '▁5000': 615,\n",
              " '▁55': 616,\n",
              " '▁6': 617,\n",
              " '▁60': 618,\n",
              " '▁60%': 619,\n",
              " '▁65': 620,\n",
              " '▁7': 621,\n",
              " '▁70': 622,\n",
              " '▁70%': 623,\n",
              " '▁8': 624,\n",
              " '▁80': 625,\n",
              " '▁80%': 626,\n",
              " '▁9': 627,\n",
              " '▁90': 628,\n",
              " '▁:': 629,\n",
              " '▁<': 630,\n",
              " '▁=': 631,\n",
              " '▁>': 632,\n",
              " '▁?': 633,\n",
              " '▁??': 634,\n",
              " '▁A': 635,\n",
              " '▁APP': 636,\n",
              " '▁B': 637,\n",
              " '▁C': 638,\n",
              " '▁CCTV': 639,\n",
              " '▁CEO': 640,\n",
              " '▁CES': 641,\n",
              " '▁CGV': 642,\n",
              " '▁CJ': 643,\n",
              " '▁D': 644,\n",
              " '▁E': 645,\n",
              " '▁ELS': 646,\n",
              " '▁ETF': 647,\n",
              " '▁F': 648,\n",
              " '▁FA': 649,\n",
              " '▁G': 650,\n",
              " '▁GS': 651,\n",
              " '▁H': 652,\n",
              " '▁HOT': 653,\n",
              " '▁Home': 654,\n",
              " '▁I': 655,\n",
              " '▁IT': 656,\n",
              " '▁J': 657,\n",
              " '▁JTBC': 658,\n",
              " '▁K': 659,\n",
              " '▁KB': 660,\n",
              " '▁KBO': 661,\n",
              " '▁KBS': 662,\n",
              " '▁KDB': 663,\n",
              " '▁KIA': 664,\n",
              " '▁KT': 665,\n",
              " '▁L': 666,\n",
              " '▁LA': 667,\n",
              " '▁LG': 668,\n",
              " '▁LIG': 669,\n",
              " '▁LTE': 670,\n",
              " '▁M': 671,\n",
              " '▁MBC': 672,\n",
              " '▁MC': 673,\n",
              " '▁Mnet': 674,\n",
              " '▁N': 675,\n",
              " '▁NC': 676,\n",
              " '▁NH': 677,\n",
              " '▁NHN': 678,\n",
              " '▁NLL': 679,\n",
              " '▁O': 680,\n",
              " '▁P': 681,\n",
              " '▁PC': 682,\n",
              " '▁PD': 683,\n",
              " '▁Q': 684,\n",
              " '▁QPR': 685,\n",
              " '▁R': 686,\n",
              " '▁S': 687,\n",
              " '▁SBS': 688,\n",
              " '▁SK': 689,\n",
              " '▁SM': 690,\n",
              " '▁SNS': 691,\n",
              " '▁STX': 692,\n",
              " '▁T': 693,\n",
              " '▁TV': 694,\n",
              " '▁U': 695,\n",
              " '▁US': 696,\n",
              " '▁V': 697,\n",
              " '▁VIP': 698,\n",
              " '▁W': 699,\n",
              " '▁XML': 700,\n",
              " '▁YG': 701,\n",
              " '▁[': 702,\n",
              " '▁`': 703,\n",
              " '▁and': 704,\n",
              " '▁c': 705,\n",
              " '▁for': 706,\n",
              " '▁of': 707,\n",
              " '▁the': 708,\n",
              " '▁to': 709,\n",
              " '▁tvN': 710,\n",
              " '▁|': 711,\n",
              " '▁‘': 712,\n",
              " '▁‘2013': 713,\n",
              " '▁“': 714,\n",
              " '▁“‘': 715,\n",
              " '▁│': 716,\n",
              " '▁■': 717,\n",
              " '▁▦': 718,\n",
              " '▁▲': 719,\n",
              " '▁△': 720,\n",
              " '▁▷': 721,\n",
              " '▁◀': 722,\n",
              " '▁◆': 723,\n",
              " '▁◇': 724,\n",
              " '▁【': 725,\n",
              " '▁中': 726,\n",
              " '▁美': 727,\n",
              " '▁가격': 728,\n",
              " '▁가격은': 729,\n",
              " '▁가격이': 730,\n",
              " '▁가계': 731,\n",
              " '▁가계부채': 732,\n",
              " '▁가구': 733,\n",
              " '▁가까운': 734,\n",
              " '▁가까이': 735,\n",
              " '▁가는': 736,\n",
              " '▁가능': 737,\n",
              " '▁가능성': 738,\n",
              " '▁가능성도': 739,\n",
              " '▁가능성을': 740,\n",
              " '▁가능성이': 741,\n",
              " '▁가능하다': 742,\n",
              " '▁가능한': 743,\n",
              " '▁가동': 744,\n",
              " '▁가득': 745,\n",
              " '▁가량': 746,\n",
              " '▁가려': 747,\n",
              " '▁가로': 748,\n",
              " '▁가르': 749,\n",
              " '▁가리': 750,\n",
              " '▁가맹점': 751,\n",
              " '▁가방': 752,\n",
              " '▁가수': 753,\n",
              " '▁가스': 754,\n",
              " '▁가슴': 755,\n",
              " '▁가시': 756,\n",
              " '▁가운데': 757,\n",
              " '▁가입': 758,\n",
              " '▁가입자': 759,\n",
              " '▁가장': 760,\n",
              " '▁가전': 761,\n",
              " '▁가정': 762,\n",
              " '▁가져': 763,\n",
              " '▁가졌다': 764,\n",
              " '▁가족': 765,\n",
              " '▁가족들': 766,\n",
              " '▁가지': 767,\n",
              " '▁가지고': 768,\n",
              " '▁가진': 769,\n",
              " '▁가짜': 770,\n",
              " '▁가치': 771,\n",
              " '▁가치를': 772,\n",
              " '▁각': 773,\n",
              " '▁각각': 774,\n",
              " '▁각자': 775,\n",
              " '▁각종': 776,\n",
              " '▁간': 777,\n",
              " '▁간담회': 778,\n",
              " '▁간부': 779,\n",
              " '▁간사': 780,\n",
              " '▁갈': 781,\n",
              " '▁갈등': 782,\n",
              " '▁갈수록': 783,\n",
              " '▁감': 784,\n",
              " '▁감각': 785,\n",
              " '▁감독': 786,\n",
              " '▁감독님': 787,\n",
              " '▁감독은': 788,\n",
              " '▁감독의': 789,\n",
              " '▁감독이': 790,\n",
              " '▁감동': 791,\n",
              " '▁감면': 792,\n",
              " '▁감사': 793,\n",
              " '▁감사원': 794,\n",
              " '▁감성': 795,\n",
              " '▁감소': 796,\n",
              " '▁감소한': 797,\n",
              " '▁감소했다': 798,\n",
              " '▁감시': 799,\n",
              " '▁감안': 800,\n",
              " '▁감안하면': 801,\n",
              " '▁감염': 802,\n",
              " '▁감정': 803,\n",
              " '▁감추지': 804,\n",
              " '▁감축': 805,\n",
              " '▁갑자기': 806,\n",
              " '▁강': 807,\n",
              " '▁강남': 808,\n",
              " '▁강남구': 809,\n",
              " '▁강력': 810,\n",
              " '▁강력한': 811,\n",
              " '▁강렬한': 812,\n",
              " '▁강릉': 813,\n",
              " '▁강세': 814,\n",
              " '▁강원': 815,\n",
              " '▁강원도': 816,\n",
              " '▁강제': 817,\n",
              " '▁강조': 818,\n",
              " '▁강조했다': 819,\n",
              " '▁강하게': 820,\n",
              " '▁강한': 821,\n",
              " '▁강행': 822,\n",
              " '▁강호동': 823,\n",
              " '▁강화': 824,\n",
              " '▁갖': 825,\n",
              " '▁갖고': 826,\n",
              " '▁갖추': 827,\n",
              " '▁갖춘': 828,\n",
              " '▁갖춰': 829,\n",
              " '▁같': 830,\n",
              " '▁같다': 831,\n",
              " '▁같아': 832,\n",
              " '▁같은': 833,\n",
              " '▁같이': 834,\n",
              " '▁개': 835,\n",
              " '▁개그맨': 836,\n",
              " '▁개념': 837,\n",
              " '▁개막': 838,\n",
              " '▁개발': 839,\n",
              " '▁개방': 840,\n",
              " '▁개별': 841,\n",
              " '▁개봉': 842,\n",
              " '▁개선': 843,\n",
              " '▁개설': 844,\n",
              " '▁개성': 845,\n",
              " '▁개성공단': 846,\n",
              " '▁개인': 847,\n",
              " '▁개인정보': 848,\n",
              " '▁개입': 849,\n",
              " '▁개장': 850,\n",
              " '▁개정': 851,\n",
              " '▁개정안': 852,\n",
              " '▁개척': 853,\n",
              " '▁개최': 854,\n",
              " '▁개최한다': 855,\n",
              " '▁개통': 856,\n",
              " '▁개편': 857,\n",
              " '▁개편안': 858,\n",
              " '▁개혁': 859,\n",
              " '▁객관적': 860,\n",
              " '▁갤럭시': 861,\n",
              " '▁거': 862,\n",
              " '▁거두': 863,\n",
              " '▁거둔': 864,\n",
              " '▁거뒀다': 865,\n",
              " '▁거듭': 866,\n",
              " '▁거래': 867,\n",
              " '▁거래되고': 868,\n",
              " '▁거래량': 869,\n",
              " '▁거론': 870,\n",
              " '▁거리': 871,\n",
              " '▁거부': 872,\n",
              " '▁거의': 873,\n",
              " '▁거절': 874,\n",
              " '▁거주': 875,\n",
              " '▁거짓말': 876,\n",
              " '▁거쳐': 877,\n",
              " '▁거치': 878,\n",
              " '▁거친': 879,\n",
              " '▁걱정': 880,\n",
              " '▁건': 881,\n",
              " '▁건강': 882,\n",
              " '▁건립': 883,\n",
              " '▁건물': 884,\n",
              " '▁건설': 885,\n",
              " '▁건설사': 886,\n",
              " '▁건축': 887,\n",
              " '▁걷': 888,\n",
              " '▁걸': 889,\n",
              " '▁걸그룹': 890,\n",
              " '▁걸린': 891,\n",
              " '▁걸스데이': 892,\n",
              " '▁걸어': 893,\n",
              " '▁걸쳐': 894,\n",
              " '▁검': 895,\n",
              " '▁검거': 896,\n",
              " '▁검사': 897,\n",
              " '▁검색': 898,\n",
              " '▁검증': 899,\n",
              " '▁검찰': 900,\n",
              " '▁검찰에': 901,\n",
              " '▁검찰은': 902,\n",
              " '▁검토': 903,\n",
              " '▁겁니다': 904,\n",
              " '▁것': 905,\n",
              " '▁것과': 906,\n",
              " '▁것도': 907,\n",
              " '▁것에': 908,\n",
              " '▁것으로': 909,\n",
              " '▁것은': 910,\n",
              " '▁것을': 911,\n",
              " '▁것이': 912,\n",
              " '▁것이다': 913,\n",
              " '▁것이라고': 914,\n",
              " '▁것이라는': 915,\n",
              " '▁것이란': 916,\n",
              " '▁것인가': 917,\n",
              " '▁것인지': 918,\n",
              " '▁것입니다': 919,\n",
              " '▁것처럼': 920,\n",
              " '▁게': 921,\n",
              " '▁게다가': 922,\n",
              " '▁게스트': 923,\n",
              " '▁게시물': 924,\n",
              " '▁게시판에': 925,\n",
              " '▁게임': 926,\n",
              " '▁게재': 927,\n",
              " '▁게재했다': 928,\n",
              " '▁겨냥': 929,\n",
              " '▁겨울': 930,\n",
              " '▁격': 931,\n",
              " '▁격려': 932,\n",
              " '▁격차': 933,\n",
              " '▁겪': 934,\n",
              " '▁겪고': 935,\n",
              " '▁견': 936,\n",
              " '▁결': 937,\n",
              " '▁결과': 938,\n",
              " '▁결과를': 939,\n",
              " '▁결국': 940,\n",
              " '▁결론': 941,\n",
              " '▁결별': 942,\n",
              " '▁결승': 943,\n",
              " '▁결심': 944,\n",
              " '▁결정': 945,\n",
              " '▁결정했다': 946,\n",
              " '▁결제': 947,\n",
              " '▁결코': 948,\n",
              " '▁결합': 949,\n",
              " '▁결혼': 950,\n",
              " '▁결혼식': 951,\n",
              " '▁겸': 952,\n",
              " '▁경': 953,\n",
              " '▁경계': 954,\n",
              " '▁경고': 955,\n",
              " '▁경기': 956,\n",
              " '▁경기가': 957,\n",
              " '▁경기도': 958,\n",
              " '▁경기를': 959,\n",
              " '▁경기에서': 960,\n",
              " '▁경기침체': 961,\n",
              " '▁경남': 962,\n",
              " '▁경력': 963,\n",
              " '▁경매': 964,\n",
              " '▁경북': 965,\n",
              " '▁경비': 966,\n",
              " '▁경영': 967,\n",
              " '▁경우': 968,\n",
              " '▁경우가': 969,\n",
              " '▁경쟁': 970,\n",
              " '▁경쟁력': 971,\n",
              " '▁경제': 972,\n",
              " '▁경제성장률': 973,\n",
              " '▁경제적': 974,\n",
              " '▁경찰': 975,\n",
              " '▁경찰관': 976,\n",
              " '▁경찰에': 977,\n",
              " '▁경찰은': 978,\n",
              " '▁경험': 979,\n",
              " '▁계': 980,\n",
              " '▁계기가': 981,\n",
              " '▁계기로': 982,\n",
              " '▁계산': 983,\n",
              " '▁계속': 984,\n",
              " '▁계약': 985,\n",
              " '▁계약을': 986,\n",
              " '▁계열사': 987,\n",
              " '▁계절': 988,\n",
              " '▁계좌': 989,\n",
              " '▁계획': 990,\n",
              " '▁계획을': 991,\n",
              " '▁계획이다': 992,\n",
              " '▁고': 993,\n",
              " '▁고객': 994,\n",
              " '▁고객들': 995,\n",
              " '▁고객에게': 996,\n",
              " '▁고교': 997,\n",
              " '▁고급': 998,\n",
              " '▁고려': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yx62B1nQXn2E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}