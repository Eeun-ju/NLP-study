{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 단어에 정수 인덱스를 부여하는 \"정수 인코딩\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    단어의 빈도수를 확인, 빈도수 순으로 차례로 낮은 숫자부터 부여할 때\n",
    "    \n",
    "    한국어 불용어 제거\n",
    "    - 한국어 같은 경우 토큰큰화 단계에서 조사나, 접속사를 제거하면 됨으로 따로 정해진 불용어가 없다. 하지만 필요없는 명사나 형용사를 제거하고 싶을 때도 있다. 이때는 직접 불용어 리스트를 정의한 다음 한국어 불용어를 제거해주면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = \"않습니다 왜나하면 되기 아 휴 아이구 아이쿠 아니 이런 여기 타다\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "text = '자연어 처리 또는 자연 언어 처리는 인간의 언어 현상을 컴퓨터와 같은 기계를 이용해서 묘사할 수 있도록 연구하고 이를 구현하는 인공지능의 주요 분야 중 하나다. 자연 언어 처리는 연구 대상이 언어 이기 때문에 당연하게도 언어 자체를 연구하는 언어학과 언어 현상의 내적 기재를 탐구하는 언어 인지 과학과 연관이 깊다. 구현을 위해 수학적 통계적 도구를 많이 활용하며 특히 기계학습 도구를 많이 사용하는 대표적인 분야이다. QA 시스템, 문서 자동 분류, 신문기사 클러스터링, 대화형 Agent 등 다양한 응용이 이루어지고 있다.'\n",
    "text = okt.nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['자연어', '처리', '자연', '언어', '처리']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "sentencse = []\n",
    "\n",
    "for i in text:\n",
    "    sentence = word_tokenize(i) # 단어 토큰화\n",
    "    result = []\n",
    "    #print(sentence)\n",
    "    #break\n",
    "    for word in sentence:\n",
    "        word = word.lower() # 단어를 소문자화 하기 \n",
    "        if word not in stop_words:\n",
    "            if len(word) > 1:\n",
    "                result.append(word)\n",
    "                \n",
    "                if word not in vocab:\n",
    "                    vocab[word] = 0\n",
    "                vocab[word] += 1\n",
    "    sentencse.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'자연어': 1, '처리': 3, '자연': 2, '언어': 7, '인간': 1, '현상': 2, '컴퓨터': 1, '기계': 1, '이용': 1, '묘사': 1, '연구': 3, '구현': 2, '인공': 1, '지능': 1, '주요': 1, '분야': 2, '하나': 1, '대상': 1, '이기': 1, '때문': 1, '자체': 1, '언어학': 1, '내적': 1, '기재': 1, '탐구': 1, '인지': 1, '과학': 1, '연관': 1, '위해': 1, '수학': 1, '통계': 1, '도구': 2, '활용': 1, '기계학습': 1, '사용': 1, '대표': 1, '시스템': 1, '문서': 1, '자동': 1, '분류': 1, '신문': 1, '기사': 1, '클러스터링': 1, '대화': 1, '응용': 1}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('언어', 7), ('처리', 3), ('연구', 3), ('자연', 2), ('현상', 2), ('구현', 2), ('분야', 2), ('도구', 2), ('자연어', 1), ('인간', 1), ('컴퓨터', 1), ('기계', 1), ('이용', 1), ('묘사', 1), ('인공', 1), ('지능', 1), ('주요', 1), ('하나', 1), ('대상', 1), ('이기', 1), ('때문', 1), ('자체', 1), ('언어학', 1), ('내적', 1), ('기재', 1), ('탐구', 1), ('인지', 1), ('과학', 1), ('연관', 1), ('위해', 1), ('수학', 1), ('통계', 1), ('활용', 1), ('기계학습', 1), ('사용', 1), ('대표', 1), ('시스템', 1), ('문서', 1), ('자동', 1), ('분류', 1), ('신문', 1), ('기사', 1), ('클러스터링', 1), ('대화', 1), ('응용', 1)]\n"
     ]
    }
   ],
   "source": [
    "#빈도가 높은 순서대로 정렬하기 \n",
    "vocab_sorted = sorted(vocab.items(), key = lambda x:x[1],reverse = True)\n",
    "print(vocab_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'언어': 1, '처리': 2, '연구': 3, '자연': 4, '현상': 5, '구현': 6, '분야': 7, '도구': 8}\n"
     ]
    }
   ],
   "source": [
    "# 빈도수가 적은 단어는 제외 높은 빈도수를 가진 단어에 낮은 인덱스 부여\n",
    "word_to_index = {}\n",
    "i = 0\n",
    "for (word,frequency) in vocab_sorted:\n",
    "    if frequency > 1:\n",
    "        i += 1\n",
    "        word_to_index[word] = i\n",
    "print(word_to_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
